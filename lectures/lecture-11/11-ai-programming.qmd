---
title: QTM 350 - Data Science Computing
subtitle: "Lecture 11 - Introduction to AI-Assisted Programming"
date: 2024-10-07
date-format: "DD MMMM, YYYY"
author:
  - name: Danilo Freire
    email: danilo.freire@emory.edu
    affiliations: Emory University
format:
  clean-revealjs:
    self-contained: true
    footer: "[AI Programming](https://raw.githack.com/danilofreire/qtm350/main/lectures/lecture-11/11-ai-programming.html)"
    drop:
      shortcut: "`"
      button: true
      engine: pyodide
      pyodide:
        packages:
          - matplotlib
          - numpy
          - pandas
transition: slide
transition-speed: default
scrollable: true
engine: jupyter
revealjs-plugins:
  - drop
  - fontawesome
filters:
  - pyodide
editor:
  render-on-save: true
---

# I hope you're having a lovely day! ðŸ˜Š {background-color="#2d4563"}

# Some comments on Quiz 2 ðŸ“š {background-color="#2d4563"}

## A few notes on Quiz 2 

:::{style="margin-top: 30px; font-size: 24px;"}
:::{.columns}
:::{.column width="50%"}
:::{.incremental}
- I haven't graded Quiz 2 yet, but I have seen most of your projects...
- ... and I'm happy with them! ðŸ˜Š
- Many of you wrote and published the website successfully, which is great!
- You indeed used different themes and styles, and the analyses were correct
- However, I noticed a few common mistakes that I'd like to address ðŸ˜‰
:::
:::

:::{.column width="50%"}
:::{.incremental}
- Most of the mistakes were actually [not related to this course's content at all!]{.alert}
- They were mainly about something that is very important in computing in general...
  - [Folder structure!]{.alert}
- Other common mistakes were:
  - Small typos in the code (e.g., missing a comma, forgetting to close the code chunk with ` ``` `, etc.)
  - Issues with pushing the changes to GitHub
- Feedback will soon be available on Canvas ðŸ˜‰
:::
:::
:::
:::

## Some tips on folder and project management

:::{style="margin-top: 30px; font-size: 20px;"}
:::{.columns}
:::{.column width="50%"}
- macOS organises files and applications in a hierarchical folder structure 
- Key system folders: `Applications`, `Library`, `System`, `Users`
- The Users folder contains individual home folders for each user
- Your home folder (e.g., `/Users/yourusername/`) contains personal folders like `Documents`, `Desktop`, `Downloads` - Access folders via Terminal:
  - Open Terminal (`Applications > Utilities > Terminal`)
  - Use `cd` command to navigate: `cd ~/Documents`
  - List contents with `ls` command
  - View current location with `pwd` command
- Common shortcuts:
  - `~` represents your home folder
  - `/` represents the root directory
:::

:::{.column width="50%"}
:::{style="text-align: center;"}
![](figures/folders.png)
![](figures/home-folder.png)
:::
:::
:::
:::

## Some tips on folder and project management

:::{style="margin-top: 30px; font-size: 20px;"}
:::{.columns}
:::{.column width="50%"}
- It is a good idea to create [a single `github` folder]{.alert} to download and manage all your Emory projects
- You should put the folder in your home directory or in `Documents`
- Inside the `github` folder, create [a folder for each course and separate folders for each project or quiz]{.alert}
- For this course, you could have a structure like this:
- `Documents`
  - `github`
    - `qtm350` (our shared repository)
    - `qtm350-quiz01` (forked repository)
    - `qtm350-quiz02` (forked repository)
- If you made a mistake and would like to start over, you can always [delete the folder and clone the repository again]{.alert}
  - That's one of the nicest things about Git and GitHub! ðŸ˜Š
:::

:::{.column width="50%"}
:::{style="text-align: center;"}
![](figures/github-folder.png)
![](figures/github-folder02.png)
:::
:::
:::
:::

# Today's lecture ðŸ¤– {background-color="#2d4563"}

## Introduction to AI-Assisted Programming

:::{style="margin-top: 30px; font-size: 24px;"}
:::{.columns}
:::{.column width="50%"}
- Yes, we all love ChatGPT! ðŸ¤–
- And LLMs (Large Language Models) are indeed changing the way we code
- This new paradigm is called [AI-Assisted Programming]{.alert}
- It is not about replacing programmers, but about making them more productive (at least for now ðŸ˜…)
- In this lecture, we will discuss the main concepts behind AI-Assisted Programming
  - What LLMs are
  - How they can help us write code
  - Limits and challenges
  - How to get started with GitHub Copilot
:::

:::{.column width="50%"}
:::{style="text-align: center;"}
![](figures/flux01.png)
:::
:::
:::
:::

## What are LLMs?

:::{style="margin-top: 30px; font-size: 21px;"}
:::{.columns}
:::{.column width="50%"}
- LLMs are a type of [neural network](https://en.wikipedia.org/wiki/Neural_network_(machine_learning)) based on the [Transformer architecture](https://arxiv.org/pdf/1706.03762) (that's the [T in GPT - Generative Pre-trained Transformer](https://arxiv.org/abs/2303.08774))
- Many important ideas behind neural networks were developed in the 1950s and 1960s (!), but the area has recently exploded due to the availability of [large datasets and powerful GPUs]{.alert}
- LLMs are trained on large corpora of text data (e.g., books, articles, websites, etc.), and they learn to predict [the next word in a sentence]{.alert}
- For code, they are trained on large repositories like GitHub and use Natural Language Processing (NLP) to understand the context and generate code snippets
- Which means that they are particularly good at writing Python or JavaScript, but they can also help with other languages
- For a very good introduction to LLMs, I strongly recommend [this article](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/) by [Stephen Wolfram](https://en.wikipedia.org/wiki/Stephen_Wolfram)
:::

:::{.column width="50%"}
:::{style="text-align: center;"}
![](figures/wolfram.png)
![](figures/wolfram02.png)
:::
:::
:::
:::

## What are LLMs?

:::{style="margin-top: 30px; font-size: 22px;"}
:::{.columns}
:::{.column width="50%"}
- So far, LLMs have made _tremendous_ progress in many areas in a very short time
- They can generate text, code, music, art, and even [new scientific discoveries](https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/)
- As we all know, what is remarkable about LLMs is not only the quality of their output, but also the fact that [they can be used by anyone, including those with no background in AI or programming]{.alert}
- Thus, LLMs are [democratising programming]{.alert} like never before
- Remember when we talked about [low and high level programming languages](https://en.wikipedia.org/wiki/High-level_programming_language)? LLMs are taking us to a new level of abstraction
- LLMs are the culmination of a long process of abstraction in computing, and [they are changing the way we think about programming]{.alert}
:::

:::{.column width="50%"}
:::{style="text-align: center;"}
![](figures/abstraction.png){width="80%"}

Source: [Taulli (2024)](https://www.oreilly.com/library/view/ai-assisted-programming/9781098164553/).

[![](figures/karpathy.png)](https://x.com/karpathy/status/1617979122625712128?lang=en)
:::
:::
:::
:::

# "Delving" into LLMs ðŸ§  {background-color="#2d4563"}

## How do LLMs work?
### A _very_ simplified explanation: Sorry mathematicians! ðŸ˜…

:::{style="margin-top: 30px; font-size: 20px;"}
:::{.columns}
:::{.column width="50%"}
:::{.incremental}
- The data collected by AI firms are huge and include [many languages and styles]{.alert}
- An overlooked part of the training process is the [data cleaning and preprocessing]{.alert}: removing duplicates, correcting errors, and standardising formats
- [Tokenisation](https://en.wikipedia.org/wiki/Tokenization_(lexical_analysis)) is the process of breaking text into smaller units called tokens, and each token is assigned a unique ID
  - For example, "`Chatbots are helpful in 2024!`" = `["Chat", "bots", "are", "help", "ful", "in", "2024", "!"]`
- The main objective during training is for the model to [predict the next token in a sequence]{.alert} based on the tokens that come before it
- This allows the model to [learn language patterns without needing labeled data]{.alert}
:::
:::

:::{.column width="50%"}
:::{style="text-align: center;"}
![](figures/tokens.png)

![](figures/unsupervised.webp)
:::
:::
:::
:::

## How do LLMs work?

:::{style="margin-top: 30px; font-size: 22px;"}
:::{.columns}
:::{.column width="50%"}
:::{.incremental}
- Models use [backpropagation](https://en.wikipedia.org/wiki/Backpropagation) to update their parameters based on the errors in their predictions
  - Backpropagation is a [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent) algorithm that adjusts the weights of the model to minimise the loss function
- They also use several methods to prevent overfitting, such as [dropout](https://en.wikipedia.org/wiki/Dropout_(neural_networks))
  - Dropout refers to randomly "dropping out", or omitting, units (both hidden and visible) during the training process of a neural network
- After initial training, the model can be [fine-tuned on specific datasets]{.alert} to improve its performance in particular domains, such as programming 
  - Often done by [poorly paid workers in developing countries](https://time.com/6247678/openai-chatgpt-kenya-workers/)
:::
:::

:::{.column width="50%"}
:::{style="text-align: center;"}
![](figures/dropout.png)

![](figures/overfitting.jpg){width="80%"}
:::
:::
:::
:::

## Why was GPT-3 so special?

:::{style="margin-top: 30px; font-size: 22px;"}
:::{.columns}
:::{.column width="50%"}
- Transformers changed the field by allowing models to [process text in parallel]{.alert}, which made them much faster than previous models
- The model consists of multiple layers, each performing specific functions to process and generate text
- GPT-3 was the first model to have [175 billion parameters]{.alert}, which made it the largest model at the time
- Another important feature was its [zero-shot leaning](https://en.wikipedia.org/wiki/Zero-shot_learning) capability, which allowed it to perform tasks without any training data
- GPT also uses [multi-head attention](https://en.wikipedia.org/wiki/Attention_(machine_learning)) to focus on different parts of the input text at the same time 
  - For example, it can focus on the subject and the verb of a sentence simultaneously
- Finally, the model also scales well with more data and more parameters
:::

:::{.column width="50%"}
:::{style="text-align: center;"}
[![](figures/sam.png)](https://x.com/sama/status/1284315896735883264?lang=en)

[![](figures/sam02.png)](https://x.com/sama/status/1284922296348454913?lang=en)
:::
:::
:::
:::


## AI-Assisted Programming: Benefits

:::{style="margin-top: 30px; font-size: 22px;"}
- The area is still very new, but we can already see some important benefits of AI-Assisted Programming:
- [Minimising search time]{.alert}: According to the [2022 Stack Overflow Developer Survey](https://insights.stackoverflow.com/survey/2022), 62% of the developers spent more than 30 minutes a day searching for answers, and 25% spent over an hour a day. Users of GitHub Copilot report that [they finish tasks 55% faster](https://github.blog/news-insights/research/research-quantifying-github-copilots-impact-on-developer-productivity-and-happiness/)
- [A 24/7 coding advisor]{.alert}: You can ask questions and get code snippets at any time, and you can also use it to learn new languages. [Results are promising](https://www.mdpi.com/2227-7102/13/4/410)
- [Easy IDE integration]{.alert}: You can use AI-Assisted Programming in your favourite IDE, and it will help you with code completion, refactoring, and debugging. [GitHub Copilot](https://copilot.github.com/) is available for Visual Studio Code, PyCharm, vim, etc
- [Reflecting your codebase and workspace]{.alert}: New tools allow you to train LLMs on your own codebase and search for files and functions in your workspace, which is a [huge benefit]{.alert} for newcomers to a team
- [Assessing code integrity]{.alert}: LLMs can identify bugs, vulnerabilities, run tests, and make suggestions
- [Language translation]{.alert}: You can write code in your language and get it translated to another language. For example, IBM's Watsonx.ai model [understands 115 coding languages based on 1.5 trillion tokens](https://www.eweek.com/it-management/modernizing-the-mainframe-ibm-introduces-watsonx-code-assistant-for-z/)
:::

## AI-Assisted Programming: Challenges
### Hallucination

:::{style="margin-top: 30px; font-size: 22px;"}
:::{.columns}
:::{.column width="50%"}
- Generative AI models can produce incorrect or misleading content
- This can be due to errors in the model, biases or incorrect information in the training data, or the limitations of the model architecture
- This makes it vital to check the output of these models and not take it at face value. For example, I asked Copilot (which is powered by OpenAI's GPT-4) to solve a simple quadratic equation, and [it very confidently gave me a very wrong answer]{.alert} ðŸ˜…
- It provided the answers of $\frac{1}{2}$ and $\frac{-5}{4}$ when the correct answers were 0.804 and -1.55. 
:::

:::{.column width="50%"}
:::{style="text-align: center;"}
![](figures/quadratic.png)
:::
:::
:::
:::

## AI-Assisted Programming: Challenges
### Bias

:::{style="margin-top: 30px; font-size: 22px;"}
:::{.columns}
:::{.column width="50%"}
- AI models can [amplify biases](https://www.scientificamerican.com/article/humans-absorb-bias-from-ai-and-keep-it-after-they-stop-using-the-algorithm/) present in the training data
- For instance, I asked an AI to give me the names of 10 famous scientists, and it came up with the following list:
  - Albert Einstein
  - Isaac Newton
  - Marie Curie
  - Charles Darwin
  - Nikola Tesla
  - Galileo Galilei
  - Stephen Hawking
  - Leonardo da Vinci
  - Thomas Edison
  - Ada Lovelace
:::

:::{.column width="50%"}
- Can you spot the bias?

:::{style="text-align: center;"}
![](figures/biases.jpg)
:::
:::
:::
:::

## AI-Assisted Programming: Challenges
### Bias

:::{style="margin-top: 30px; text-align: center;"}
![](figures/biases02.png){width="75%"}

<https://www.nature.com/articles/s41598-023-42384-8>
:::

## AI-Assisted Programming: Challenges
### Easy to confuse

:::{style="margin-top: 30px; font-size: 22px;"}
:::{.columns}
:::{.column width="50%"}
- AI models can be [easily confused](https://www.technologyreview.com/2022/07/07/1045821/ai-bias-ethics/) by small changes in the input
- AIs have an annoying tendency to be overpolite and [agree with you even when you are wrong]{.alert}
- Thus, they can be easily manipulated (including by bad actors)
- For example, I asked Copilot what the westernmost point of Europe was, and contradicted its answer
:::

:::{.column width="50%"}
:::{style="text-align: center;"}
![](figures/europe.png)
:::
:::
:::
:::

## AI-Assisted Programming: Challenges
### Intellectual property

:::{style="margin-top: 30px; font-size: 22px;"}
:::{.columns}
:::{.column width="50%"}
- AI models can generate code that is [identical to existing code]{.alert}
- This raises questions about [intellectual property](https://apnews.com/article/ai-media-lawsuits-center-for-investigative-reporting-chatgpt-mother-jones-c48452889750479410b65a119537746c) and the [ownership of the code]{.alert}
- This is an ongoing debate in the AI community, and it is not clear how it will be resolved
- But it does have some important implications for open source software and the sharing of code
:::

:::{.column width="50%"}
:::{style="text-align: center;"}
![](figures/stupid.png)

More here: <https://matthewbutterick.com/chron/this-copilot-is-stupid-and-wants-to-kill-me.html>
:::
:::
:::
:::

## AI-Assisted Programming: Challenges
### Security

:::{style="margin-top: 30px; font-size: 22px;"}
:::{.columns}
:::{.column width="50%"}
- AI models can be vulnerable to [adversarial attacks](https://en.wikipedia.org/wiki/Adversarial_machine_learning) and [injection attacks](https://en.wikipedia.org/wiki/Code_injection)
- As programmers use more AI-generated code, many blindly trust the output of these models and send the code into production
- In [Security Weaknesses of Copilot Generated Code in GitHub](https://arxiv.org/abs/2310.02059), Yujia Fu et al. highlighted the security issues with GitHub Copilot.
- They evaluated 435 AI-generated code snippets from projects on GitHub, and 35.8% had security vulnerabilities
- ...and this code is all going to the LLMs! ðŸ˜…
:::

:::{.column width="50%"}
:::{style="text-align: center;"}
![](figures/security.png)

More here: <https://www.techrepublic.com/article/ai-generated-code-outages/>
:::
:::
:::
:::

# Can we prevent these issues? ðŸ¤” {background-color="#2d4563"}

## How to prevent some of these issues 
### Better prompt engineering

:::{style="margin-top: 30px; font-size: 20px;"}
:::{.columns}
:::{.column width="50%"}
- [Prompt engineering](https://platform.openai.com/docs/guides/prompt-engineering) is a new buzzword in the AI community
- It refers to the process of designing the input to an AI model to get the desired output
- It is, to a large extent, [a mix of art and science]{.alert} that involves _a lot_ of trial and error (at least in my experience!)
- The idea is to [guide the model to produce the desired output]{.alert} by providing it with the right context and examples
- Prompt engineering will never be fully exact simply because [models themselves are probabilistic](https://en.wikipedia.org/wiki/Probabilistic_model)
- But you can think of a prompt as having [four main components]{.alert}:
:::

:::{.column width="50%"}
:::{style="text-align: center;"}
![](figures/components.png)

Source: [Tulio (2024)](https://www.oreilly.com/library/view/ai-assisted-programming/9781098164553/).

- [Context]{.alert}: The information you provide to the model
- [Instructions]{.alert}: The task you want the model to perform
- [Input of the model]{.alert}: The data you feed into the model
- [Format]{.alert}: The structure of the prompt
:::
:::
:::
:::

## Context

:::{style="margin-top: 30px; font-size: 22px;"}
:::{.columns}
:::{.column width="50%"}
- It is a good idea to begin your prompt with a sentence or two that [clearly defines the task]{.alert} you want the model to perform
- [Creating a persona]{.alert} for the model can also help guide its output
  - Prompt: You are an experienced software engineer specialising in debugging Python code. You are asked to write a function that takes a list of integers and returns the sum of the even numbers.
- Personal note: I've had good results by [adopting multiple personas]{.alert} in the same prompt
  - For example, I might ask the model to write a function as if it were a beginner, an intermediate, and an expert programmer and then compare the results
:::

:::{.column width="50%"}
:::{style="text-align: center;"}
![](figures/context.png)

Source: <https://chatgpt.com/share/6e0c2115-6fd0-497d-a662-44cb0434cee2>
:::
:::
:::
:::

## Instructions

:::{style="margin-top: 30px; font-size: 22px;"}
:::{.columns}
:::{.column width="50%"}
- Your prompt should include at least one [clear and concise instruction]{.alert}
- [Fewer instructions are better]{.alert} because they reduce the chances of the model getting confused
- You can also use [examples]{.alert} to guide the model
  - Prompt: Develop a SQL query to retrieve from our database a list of customers who made purchases above $500 in the last quarter of 2023. The query should return the customerâ€™s full name, their email address, the total amount spent, and the date of their last purchase. The results should be sorted by the total amount spent in descending order. Please ensure that the query is optimized for performance.
:::

:::{.column width="50%"}
:::{style="text-align: center;"}
![](figures/prompt-elements.png)

Source: <https://learn.microsoft.com/en-us/copilot/security/prompting-tips>
:::
:::
:::
:::

## Input of the model

:::{style="margin-top: 30px; font-size: 22px;"}
:::{.columns}
:::{.column width="50%"}
- The input of the model is the data you feed into it
- Use [keywords]{.alert} that are relevant to the task you want the model to perform
- When it comes to coding, you can provide the model with [code snippets]{.alert} that it can use as a reference
- Also pay attention to delimiters and separators, as they can help the model understand the structure of the input
- For example, you can use [comments]{.alert} to provide additional information to the model
:::

:::{.column width="50%"}
:::{style="text-align: center;"}
![](figures/instructions.png)

Source: <https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api>
:::
:::
:::
:::

## Format

:::{style="margin-top: 30px; font-size: 22px;"}
:::{.columns}
:::{.column width="50%"}
- Finally, you can also be explicit about the format you want the output to be in
- For example, you can specify that you want the output to be in a [specific programming language]{.alert}, or you can ask the model to provide you with a [code snippet]{.alert}
- You can also ask the model to provide you with a [list of steps]{.alert} to complete a task
- This can be useful if you are working on a complex project or with different programming languages
:::

:::{.column width="50%"}
:::{style="text-align: center;"}
![](figures/format.png)
:::
:::
:::
:::

# How to get started with GitHub Copilot ðŸš€ {background-color="#2d4563"}

## How to get started with GitHub Copilot

:::{style="margin-top: 30px; font-size: 22px;"}
:::{.columns}
:::{.column width="50%"}
- We will look into Copilot in more detail in the next lecture, but I just want to make sure we all have it installed and ready to go ðŸ˜‰
- First, it is a good idea to have [VS Code](https://code.visualstudio.com/) installed on your computer
- Then, you can install the [GitHub Copilot extension](https://marketplace.visualstudio.com/items?itemName=GitHub.copilot) from the VS Code marketplace
- You will need to [sign in with your GitHub account](https://github.com) to use Copilot
- Copilot works in the CLI as well, and you can install it using [this guide](https://docs.github.com/en/copilot/using-github-copilot/using-github-copilot-in-the-command-line). You need to install [GitHub CLI](https://cli.github.com/) first
- Take some time to install and play around with Copilot before the next lecture ðŸ˜ƒ
- Please let me know if you have any questions or issues!
:::

:::{.column width="50%"}
:::{style="text-align: center;"}
![](figures/copilot.jpeg)

<https://github.com/features/copilot>
:::
:::
:::
:::

## Basic components

:::{style="margin-top: 30px; font-size: 22px;"}
:::{.columns}
:::{.column width="50%"}
- There are two main components to GitHub Copilot:
  - GitHub Copilot: This provides code suggestions and completions in the editor window
  - GitHub Copilot Chat: This provides a chat interface to Copilot, allowing you to ask questions and get code suggestions. It can also interact with code in the editor window. [This is by far the most powerful feature of Copilot]{.alert}
- Copilot not only offers code suggestions, but it can also help you with writing documentation, providing explantions for code you don't know, and, more recently, retrieving code snippets and information from your whole workspace
- In my view, it is the most convenient AI-assistant for programming available today
- It is also [very easy to use](https://docs.github.com/en/copilot/getting-started-with-github-copilot)
:::

:::{.column width="50%"}
:::{style="text-align: center;"}
![](figures/unexpectedcopilot2.webp)
:::
:::
:::
:::

## Autocompletion

:::{style="margin-top: 30px; font-size: 21px;"}
:::{.columns}
:::{.column width="50%"}
- If you start writing code in the editor, and Copilot will suggest completions
- You can accept these completions by pressing `Tab` or `Enter`
- Alternatively, you can press `Ctrl` and the right arrow key to select just the next word T
- This can be helpful if some, but not all, of the suggestion is appropriate
- This autocompletion will work in a number of different contexts, including code cells in Jupyter Notebooks, or within a .py file.
- The autocompletion is aware of the code around your cursor, and will suggest completions based on this context I
- It can use functions already in the code, and can infer a likely purpose of the next piece of code based on the code that has already been written 
- Sometimes, writing a comment will help guide Copilot to suggest relevant code to you
:::

:::{.column width="50%"}
:::{style="text-align: center;"}
![](figures/autocomplete.gif)

Source: <https://github.com/ImperialCollegeLondon/RCDS-introduction-to-AI-assisted-programming/blob/main/resources/autocomplete.gif>
:::
:::
:::
:::

## In-Editor Prompting

:::{style="margin-top: 30px; font-size: 21px;"}
- In an empty file/code cell, VS Code will display a greyed-out piece of text as follows:

![](figures/prompt_invitation.png)

- If you press `Ctrl + I`, a text box will appear into which you can write a prompt C
- Copilot will suggest new code, or changes to existing code based on this prompt
- These may be in the form of one or more proposed changes
- You may choose to accept ach of these changes by clicking the Accept or Discard buttons

![](figures/bubble_sort.png)
:::

## In-Editor Prompting

:::{style="margin-top: 30px; font-size: 21px;"}
- You can also highlight an existing piece of code and press `Ctrl + I` to ask Copilot to suggest changes to that code 
- This can be useful if you have a piece of code that you think could be improved, or if you want to see alternative ways of writing the same code
- When you do this, you can also click on the button next to Accept and Discard to see which code Copilot is suggesting removing for each change

![](figures/relative_std.gif)
:::

## In-Editor Prompting

:::{style="margin-top: 30px; font-size: 21px;"}
- There are a few standard commands that are available for prompting Copilot to do something when you have a piece of code selected
- You can access these in the `Ctrl + I` interface by typing a forward slash, then the name of the command. These are:
 - `/doc`: This will ask Copilot to generate documentation for the selected code. This will suggest changes in the editor 
 - `/explain`: This will ask Copilot to explain the selected code. It will do this in the Copilot Chat extension
 -  `/fix` will look for problems in the selected code and suggest fixes for them in the editor.
 -  `/test` will ask Copilot to generate tests for the selected code. This will suggest changes in the editor, which may include creating a new file for the tests

- You can also find these options by right-clicking a highlighted piece of code, and going into the Copilot menu

- We'll look at using some of these tools later in the course
:::

## Copilot Chat

:::{style="margin-top: 30px; font-size: 21px;"}
- You can also chat to Copilot in a manner closer to that of a chatbot like ChatGPT
- To do this, you can open the chat window by clicking on the chat icon in the activity bar at the left of the screen

![](figures/copilot_chat_icon.png){width="5%"}

- You can type a message to Copilot in the window and it will respond, including suggesting code snippets where relevant
- Copilot chat is limited to discussing programming
- If Copilot produces a code snippet that you want to use, you can hover over the snippet and click the "Copy" button to copy it to the clipboard, click the "Insert at Cursor" button to insert at the location of the cursor in the editor, or insert it into a new file or the currently active terminal

![](figures/chat_inserting_code.png){width="65%"}
:::

## Exercise
### You can work on this exercise on your own time

:::{style="margin-top: 30px; font-size: 22px;"}
- Experiment with some of the ways of using Copilot that we have discussed in this notebook. Include the following activities:
  - Use the Ctrl + I interface to ask Copilot to generate a function from scratch.
  - Use the Ctrl + I interface to ask Copilot a question about an existing piece of code.
  - Use autocomplete to complete a function that you have started writing.
  - Ask Copilot Chat a general question about programming.
  - Ask Copilot Chat a question about a specific piece of code.
  - Insert some code produced by Copilot Chat into the code cell.
:::

# That's all for today! ðŸŽ‰ {background-color="#2d4563"}

# Next time we will learn what Copilot can do for us! ðŸ¤– {background-color="#2d4563"}

# Have a great day! ðŸ˜Š {background-color="#2d4563"}

